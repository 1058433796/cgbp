{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f664fc",
   "metadata": {
    "id": "04f664fc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchsummary import summary\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a428840",
   "metadata": {
    "id": "7a428840"
   },
   "outputs": [],
   "source": [
    "# Const variables\n",
    "\n",
    "# Dataset root\n",
    "DATASET_DIR_ROOT = \"./dataset\"\n",
    "\n",
    "# Number of epochs\n",
    "n_epochs = 80\n",
    "\n",
    "# Input images size\n",
    "image_size = 224\n",
    "\n",
    "# Number of batches\n",
    "batch_size = 32\n",
    "\n",
    "# Number of workers for dataloaders\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C83Fl2yDxOAh",
   "metadata": {
    "id": "C83Fl2yDxOAh"
   },
   "source": [
    "# **DATA LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5c6dc",
   "metadata": {
    "id": "0fc5c6dc"
   },
   "outputs": [],
   "source": [
    "# Define transforms for each dataset separately\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),  # 调整大小\n",
    "    transforms.CenterCrop(224),  # 中心裁剪\n",
    "    transforms.ToTensor(),  # 转为Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9add9e5",
   "metadata": {
    "id": "e9add9e5"
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_set = datasets.ImageFolder(\n",
    "    root=os.path.join(DATASET_DIR_ROOT, \"train\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "validation_set = datasets.ImageFolder(\n",
    "    root=os.path.join(DATASET_DIR_ROOT, \"validation\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_set = datasets.ImageFolder(\n",
    "    root=os.path.join(DATASET_DIR_ROOT, \"test\"),\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28315621",
   "metadata": {
    "id": "28315621"
   },
   "outputs": [],
   "source": [
    "# Instantiate DataLoaders\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    dataset=validation_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arKZYauewzXk",
   "metadata": {
    "id": "arKZYauewzXk"
   },
   "source": [
    "# **DATA VISUALIZATION** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3Lsd5LUwnT-e",
   "metadata": {
    "id": "3Lsd5LUwnT-e"
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ia5Thlije7oX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "Ia5Thlije7oX",
    "outputId": "87cb9328-8b84-4955-dca1-935b01edf06c"
   },
   "outputs": [],
   "source": [
    "def grid_display(dataloader):\n",
    "    \"\"\"Plots a single batch of a dataloader. Denormalizes images for better visualization.\n",
    "\n",
    "    :param dataloader: a DataLoader object that we want to display its images\n",
    "    \"\"\"\n",
    "    for images, labels in dataloader:\n",
    "        fig, ax = plt.subplots(figsize = (16,12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=8).permute(1,2,0))\n",
    "        break\n",
    "        \n",
    "# grid_display(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65724f9f",
   "metadata": {
    "id": "65724f9f"
   },
   "outputs": [],
   "source": [
    "def label_distribution(dataset):\n",
    "    \"\"\"Counts the number of samples per label(class) in the dataset.\n",
    "    \n",
    "    :param dataset: the purpose dataset\n",
    "    :type dataset: ImageFolder\n",
    "    \"\"\"\n",
    "    encoded_labels = {v:k for k, v in dataset.class_to_idx.items()} # {0: 'cataract', 1: 'diabetic_retinopathy', 2: 'glaucoma', 3: 'normal'}\n",
    "    labels_count = {k:0 for k in dataset.class_to_idx} # {'cataract': 0, 'diabetic_retinopathy': 0, 'glaucoma': 0, 'normal': 0}\n",
    "\n",
    "    for label_code in encoded_labels:\n",
    "        labels_count[encoded_labels[label_code]] = dataset.targets.count(label_code)\n",
    "    return labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7131a3",
   "metadata": {
    "id": "ae7131a3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_from_dict(dict_obj: dict, plot_title: str, **kwargs):\n",
    "    \"\"\"Plots a bar chart from a dictionry. keys: x_axis, values: y_axis\n",
    "    \n",
    "    :param dict_obj: the dictionary that would be plotted\n",
    "    :param plot_title: title of the plot\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict([dict_obj]).melt()\n",
    "    df.rename(columns={'variable': 'Dataset Labels', 'value': 'Number of samples'}, inplace=True)\n",
    "    return sns.barplot(\n",
    "        data=df,\n",
    "        x=\"Dataset Labels\",\n",
    "        y=\"Number of samples\",\n",
    "        hue=\"Dataset Labels\",\n",
    "        **kwargs\n",
    "    ).set_title(label=plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85400166",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "85400166",
    "outputId": "2cc72c93-5e3d-4cac-cb59-b56dafdf8608"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 20))\n",
    "plot_from_dict(label_distribution(train_set), plot_title=\"Train Set\", ax=axes[0])\n",
    "plot_from_dict(label_distribution(validation_set), plot_title=\"Validation Set\", ax=axes[1])\n",
    "plot_from_dict(label_distribution(test_set), plot_title=\"Test Set\", ax=axes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ODDSGmYtvnBb",
   "metadata": {
    "id": "ODDSGmYtvnBb"
   },
   "source": [
    "# **MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b14a6-b02d-4cd9-b691-88dbf0382bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResnet(nn.Module):\n",
    "    def __init__(self, num_class, frozen=True):\n",
    "        super(MyResnet, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, self.num_class)\n",
    "        )\n",
    "        if frozen:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False  # 冻结所有层\n",
    "\n",
    "            # 只训练最后的全连接层\n",
    "            for param in self.model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9553c5f5-041e-477a-9730-10403b6b1b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary of the architecture of RetinalEnsemble\n",
    "\n",
    "# summary(EyeSeeNet(4), (3, image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad20642",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ad20642",
    "outputId": "f7c03c58-b66e-4397-e532-b0896e2cefce"
   },
   "outputs": [],
   "source": [
    "# Define device : GPU, MPS, or CPU\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af48a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48af48a3",
    "outputId": "15bc5469-2b1b-4898-d876-e0d834d2692e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instanciate and Transfer model on the device\n",
    "\n",
    "model = MyResnet(4, frozen=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14e79a",
   "metadata": {
    "id": "fd14e79a"
   },
   "outputs": [],
   "source": [
    "# Loss & Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zm0_b43MvDb-",
   "metadata": {
    "id": "Zm0_b43MvDb-"
   },
   "source": [
    "# **TRAIN THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f14ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "252f14ee",
    "outputId": "40860ecf-dd5b-4ceb-ea85-5f587d77460f"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "train_losses = np.zeros(n_epochs)\n",
    "val_losses = np.zeros(n_epochs)\n",
    "best_val_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_corrects = 0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for inputs, targets in tqdm(train_loader, desc=f'Training... Epoch: {epoch + 1}/{n_epochs}'):\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_corrects += torch.sum(preds == targets.data)\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = train_corrects / len(train_loader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_corrects = 0\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        for inputs, targets in tqdm(validation_loader, desc=f'Validating... Epoch: {epoch + 1}/{n_epochs}'):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == targets.data)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        val_loss = val_loss / len(validation_loader.dataset)\n",
    "        val_acc = val_corrects / len(validation_loader.dataset)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # save epoch losses\n",
    "    train_losses[epoch] = train_loss\n",
    "    val_losses[epoch] = val_loss\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "    print('-'*30)\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o1UpAb80T1rP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "o1UpAb80T1rP",
    "outputId": "6d56d643-e79f-4593-b22a-11b24835e25a"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train loss\")\n",
    "plt.plot(val_losses, label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5jkEEoG3uYoN",
   "metadata": {
    "id": "5jkEEoG3uYoN"
   },
   "source": [
    "# **TEST & EVALUATION**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Rbe4NrTSXITM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rbe4NrTSXITM",
    "outputId": "3ca77c7e-dca6-4632-a7cf-df54b171d9ef",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-17T06:44:42.795472Z",
     "start_time": "2024-12-17T06:44:10.467789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9769, Validation Accuracy: 0.8641, Test Accuracy: 0.8756\n"
     ]
    }
   ],
   "source": [
    "# Calculate Train and Validation Accuracy\n",
    "\n",
    "def cal_accuracy(data_loader):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    \n",
    "    for inputs, targets in data_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        n_correct += (predictions == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "\n",
    "    accuracy = n_correct / n_total\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "print(f\"Train Accuracy: {cal_accuracy(train_loader):.4f}, Validation Accuracy: {cal_accuracy(validation_loader):.4f}, Test Accuracy: {cal_accuracy(test_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qRLf7k4biVem",
   "metadata": {
    "id": "qRLf7k4biVem",
    "ExecuteTime": {
     "end_time": "2024-12-17T06:44:49.000820Z",
     "start_time": "2024-12-17T06:44:42.797989Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        y_true_list.append(targets.cpu().numpy())\n",
    "        y_pred_list.append(predictions.cpu().numpy())\n",
    "\n",
    "# flatten data of batches into a 1-d list\n",
    "y_true_list = list(np.concatenate(y_true_list).flat)\n",
    "y_pred_list = list(np.concatenate(y_pred_list).flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "IMqP0aerpu1w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMqP0aerpu1w",
    "outputId": "1dc4a7e6-a175-400c-fbb7-350eff963f6e",
    "ExecuteTime": {
     "end_time": "2024-12-17T06:44:49.016777Z",
     "start_time": "2024-12-17T06:44:49.002814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       156\n",
      "           1       0.94      0.94      0.94       165\n",
      "           2       0.85      0.77      0.81       152\n",
      "           3       0.81      0.87      0.84       162\n",
      "\n",
      "    accuracy                           0.88       635\n",
      "   macro avg       0.88      0.87      0.87       635\n",
      "weighted avg       0.88      0.88      0.88       635\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "\n",
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahyIT9YcqCKR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahyIT9YcqCKR",
    "outputId": "3e195f77-3dfd-4f95-af4d-fceb11c23927"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "print(confusion_matrix(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HTb9gaDLqKk2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "HTb9gaDLqKk2",
    "outputId": "db15340d-6530-485c-e170-d97592ac66c1"
   },
   "outputs": [],
   "source": [
    "# Plot the Confusion Matrix\n",
    "\n",
    "def plot_confusion_matrix(dataset, y_true_list, y_pred_list):\n",
    "    index_to_label = {v:k for k, v in dataset.class_to_idx.items()}\n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true_list, y_pred_list)).rename(columns=index_to_label, index=index_to_label)\n",
    "    fig, ax = plt.subplots(figsize=(14,10))         \n",
    "    return sns.heatmap(confusion_matrix_df, annot=True, ax=ax)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(test_set, y_true_list, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"myresnet.pth\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ab492e669fcce43",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "509f1c90-7e2a-4c74-a730-ae079795a50a",
   "metadata": {},
   "source": [
    "# **MISCLASSIFIED SAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c9fec-62d6-41e7-9844-579cc6e3205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some of misclassified instances\n",
    "\n",
    "n_missclassified = 25\n",
    "\n",
    "encoded_labels = {v:k for k, v in train_set.class_to_idx.items()}\n",
    "misclassified_idx = np.where(np.array(y_true_list) != np.array(y_pred_list))[0]\n",
    "\n",
    "print(f\"{n_missclassified} of Misclassified Images:\")\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i, mis_index in enumerate(misclassified_idx[:n_missclassified]):\n",
    "    ax = axes.ravel()[i]\n",
    "    ax.imshow(test_set[mis_index][0].permute(1, 2, 0))\n",
    "    ax.set_title(f\"True: {encoded_labels[y_true_list[mis_index]]}\\nPredicted: {encoded_labels[y_pred_list[mis_index]]}\")\n",
    "    ax.axis('off')\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
